{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as nprand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Racer\n",
    "\n",
    "In this notebook, you'll apply the methods of chapter 3 of Sutton's book to a simple racing problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem consists in driving a car as fast of possible over an exact distance $L$, and stopping there.\n",
    "\n",
    "This distance is divided in steps $0, ..., L$. The car can drive at three different speed: _low_, _medium_, _high_. Leaving step $j$ at _low_ speed, it will move to $j+1$. _Medium_ and _high_ bring it to $j+2$ and $j+3$, respectively.\n",
    "\n",
    "At any step, the driver can decide to _decelerate_, _maintain speed_ or _accelerate_. Decelarating will cause the car to leave its current place at one speed lower. If the car is already at _low_ speed, decelarating keeps it in the same spot. Maintaining speed does exactly what you think. Accelerating will increase the speed by one, except at _high_ speed, where it is equivalent to maintaining speed.\n",
    "\n",
    "The car starts on step $0$ at _low_ speed.\n",
    "\n",
    "Beyond the $L$ distance there is a huge, hot lake of lava. Needless to say, the car must be able to stop at $L$, or the driver will suffer quite a lot."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    car ->                    ||/\\/\\/\n",
    "     |_______________ ... ____||/\\/ lava\n",
    "     |    |    |    |       | ||/\\/\\/\n",
    "     0    1    2    3       L ||/\\/\\/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help the driver win the race and not die, build a model of the problem and apply the policy iteration and value iteration methods to find her optimal trajectory.\n",
    "\n",
    "As this problem is an (over-)simplification of our traffic light problem, any work done here could serve as a building block for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by figuring out the number of states you will need and build transition matrices for every action. For now, actions move the car from state to state in the deterministic manner described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T_decelerate = np.zeros(shape=(3*l, 3*l))\n",
    "T_maintain = np.zeros(shape=(3*l, 3*l))\n",
    "T_accel = np.zeros(shape=(3*l, 3*l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the matrix repeats itself for each action :  (here the decelerate matrix)\n",
    "\\begin{pmatrix}1&0&0 & 0&0&0 & 0&0&0 &  0&0&0 & \\ldots \n",
    "\\\\ 0&0&0 & 1&0&0 & 0&0&0 &  0&0&0 & \\ldots \n",
    "\\\\ 0&0&0 & 0&0&0 & 0&1&0 &  0&0&0 & \\ldots\n",
    "\\\\ 0&0&0 & 1&0&0 & 0&0&0 &  0&0&0 & \\ldots\n",
    "\\\\ 0&0&0 & 0&0&0 & 1&0&0 &  0&0&0 & \\ldots\n",
    "\\\\ 0&0&0 & 0&0&0 & 0&0&0 &  0&1&0 & \\ldots\n",
    "\\end{pmatrix}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(T_decelerate)-5):\n",
    "    if (i%3==0 ):\n",
    "        T_decelerate[i][i]=1\n",
    "    if (i%3==1):\n",
    "        T_decelerate[i][i+2]=1\n",
    "    if (i%3==2):\n",
    "        T_decelerate[i][i+5]=1\n",
    "\n",
    "n=len(T_decelerate)\n",
    "T_decelerate[n-5][n-3]=1\n",
    "T_decelerate[n-3][n-3]=1\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_decelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define the reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.zeros(?)\n",
    "R[?] = [?] etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the policy iteration procedure to figure out the best policy to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_eval(?):\n",
    "    # write your policy eval algo here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def policy_improv(?):\n",
    "    # write your policy improv algo here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the two functions to iterate over policies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# policy iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out if everything is going well, make sure that at each iteration you keep track of the value vector, as well as the trajectory of the car according to the current policy. The latter allows you to compute the current policy's total reward and plot the evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the stored values to make a video similar to _street_racer.mp4_ on the repo. The following procedure can be used to save figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, v in enumerate(values):\n",
    "    v = np.array(v[:trap]).reshape(3, l)\n",
    "    fig = plt.figure(figsize=(l*2, 6), dpi=72)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(v, interpolation='nearest', cmap='gray')\n",
    "    plt.yticks([])\n",
    "    plt.savefig('img/value_'+str(idx)+'.jpg', dpi=72, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the command-line utility _ffmpeg_ and use it to transform the saved sequence of images into a mp4 video.\n",
    "\n",
    "(https://en.wikibooks.org/wiki/FFMPEG_An_Intermediate_Guide/image_sequence#Making_a_video_from_an_Image_Sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with your model. What happens if you introduce uncertainty about the car's brakes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
